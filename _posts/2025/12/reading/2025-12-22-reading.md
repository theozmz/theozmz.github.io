---
title: 'Reading: Memory in the Age of AI Agents: A Survey'
date: 2025-12-22
permalink: /posts/2025/12/reading/
tags:
  - memory
  - LLM
  - survey
---

This is a survey paper from NUS, Tongji University and so on. It introduces the development of memory mechanism of AI agents in three ways: forms, functions and dynamics. It also introduces several benchmarks, frameworks and the history of memory mechanism. Its title is "**Memory in the Age of AI Agents: A Survey**". It has a subtitle "**Forms, Functions and Dynamics**", which emphasizes their taxonomy. The paper is available [here](https://arxiv.org/abs/2512.13564). The code is available [here](https://github.com/Shichun-Liu/Agent-Memory-Paper-List).

Abstract:
> Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. It underpins long-horizon reasoning, continual adaptation, and effective interaction with complex environments. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, assumptions, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity and dynamics of contemporary agent memory systems. This survey aims to provide an up-to-date and comprehensive landscape of current agent memory research. We begin by clearly delineating the scope of agent memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine agent memory through the unified lenses of **forms**, **functions**, and **dynamics**. From the perspective of forms, we identify three dominant realizations of agent memory, namely token-level, parametric, and latent memory. From the perspective of functions, we move beyond coarse temporal categorizations and propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time as agents interact with their environments. To support empirical research and practical development, we compile a comprehensive summary of representative benchmarks and open source memory frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including automation-oriented memory design, the deep integration of reinforcement learning with memory systems, multimodal memory, shared memory for multi-agent systems, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence.

![frameworks and benchmarks](./pics/main.png)

* **Forms**: What architectural or representational forms can agent memory take?
* **Functions**: Why is agent memory needed, and what roles or purposes does it serve?
* **Dynamics**: How does agent memory operate, adapt, and evolve over time?

Some definitions:
* **Environment**: a state space, a controlled stochastic transition model, an observation equation consisting of states, history, and tasks
* **Action**: A strategy consisting of observation, memory derived signal, and task
* **Trajectory**: Status, Observation, and Action
* **Memory lifecycle**: Formation formation, Evolution, and Retrieval

The memory is catogrized into four classes:

![concept](./pics/concept.png)
* **Agent memory**: The intelligent agent has a "persistent write/read/update/forget" memory system, which is used to precipitate information across tasks and sessions.
* **LLM memory**: The context window mechanism within LLM, which refers to the limited information that LLM can remember in a single conversation.
* **RAG**: Retrieval Enhanced Generation, a technique that combines LLM with an external knowledge base to enhance LLM output by retrieving relevant documents as context.
* **Context engineering**: A systematic approach to improving model performance by retrieving, organizing, and optimizing the information required for model inference.

**Forms**: What architectural or representational forms can agent memory take?

|Features | Symbol level memory | Embedding level memory | Database level memory|
| ------------ | ------------------ | ------------------ | ------------------ |
| **Storage format** | Natural language text | Vector | Structured data|
| **Search Method** | Keyword Matching | Semantic Similarity | SQL Query|
| **Readability** | High | Low | Medium|
| **Semantic understanding** | Limited | High | Limited|
| **Storage efficiency** | Low | High | Medium|
| **Typical Applications** | Task Summary, Dialogue History | User Preferences, Long Term Memory | State Storage, User Information|

**Functions**: Why is agent memory needed, and what roles or purposes does it serve?

* **Factual Memory**: Addressing 'What I Know' and Maintaining Consistency.
* **Experiential Memory**: Solving the Problem of 'How I Became Strong' and Achieving Evolution.
* **Working Memory**: Addressing 'What I'm Thinking' and Dealing with Current Tasks.

**Dynamics**: How does agent memory operate, adapt, and evolve over time?

* **Memory Formation**: How to Transform Massive Interactive Data into Valuable Memories.
* **Memory Evolution**: How Memory Banks Change Over Time to Avoid 'Memory Overload'.
* **Memory Retrieval**: How to Find the Required Memory.